# OTLP Cardinality Checker - Product Document

## Problem Statement

OpenTelemetry telemetry kan snabbt bli oh√•llbar n√§r instrumentering introducerar h√∂ga kardinalitetsattribut. Detta leder till:

- **Ov√§ntade kostnader** i observability-backends (Prometheus, Datadog, etc.)
- **Performance-problem** i collectors och backends
- **Sv√•righeter att identifiera k√§llan** till kardinalitetsproblem
- **Reaktiv problemhantering** ist√§llet f√∂r proaktiv √∂vervakning

Det saknas verktyg som enkelt kan inspektera och f√∂rst√• **vilken metadata-struktur** som faktiskt skickas via OTLP innan data n√•r produktionssystem.

## Solution

OTLP Cardinality Checker √§r ett lightweight analysverktyg skrivet i Go som:

1. **Tar emot OTLP-telemetri** via gRPC och HTTP (som en standard OTLP-endpoint)
2. **Extraherar metadata-struktur** fr√•n all inkommande telemetri
3. **Lagrar och visualiserar** vilka nycklar och attribut som anv√§nds
4. **Ger insikter** om potentiella kardinalitetsproblem

### Vad analyseras

#### Metrics
- Metric name
- Alla unika label-nycklar (inte v√§rden)
- Resource attributes (nycklar)
- Scope/instrumentation library info

#### Logs  
- Unika nycklar i resource attributes
- Unika nycklar i log attributes
- Body struktur ignoreras (f√∂r att undvika h√∂ga volymer)

#### Traces
- Unika span names
- Unika nycklar i span attributes
- Unika nycklar i resource attributes
- Event och link attribute nycklar

### Vad analyseras INTE

- **Inga v√§rden** lagras (f√∂r att undvika kardinalitetsexplosion i verktyget sj√§lv)
- **Ingen time-series data** - fokus √§r p√• struktur, inte m√§tv√§rden
- **Ingen full trace reconstruction** - bara metadata

## Target Audience

### Primary Users
- **Platform Engineers** som ansvarar f√∂r observability-infrastruktur
- **SRE Teams** som beh√∂ver f√∂rst√• telemetrikostnader
- **DevOps Engineers** som troubleshooting instrumentering

### Use Cases
1. **Pre-production validation** - Verifiera metadata innan deploy
2. **Cost analysis** - F√∂rst√• vad som driver observability-kostnader
3. **Instrumentation debugging** - Identifiera over-instrumented services
4. **Metadata governance** - S√§kerst√§ll att teams f√∂ljer attribute conventions

## Key Features

### 1. OTLP-Kompatibel HTTP Receiver
- **HTTP** support (port 4318) ‚úÖ **IMPLEMENTED**
- **gRPC** (port 4317) üîú **PLANNED FOR PHASE 2**
- Fullt kompatibel med OpenTelemetry Collector OTLP HTTP exporter
- Fungerar som analysverktyg mellan Collector och backend

### 2. Metadata Extraction
- Real-time parsing av OTLP protobuf
- Automatisk uppt√§ckt av nya nycklar
- Ingen sampling - all metadata analyseras

### 3. Efficient Storage
- In-memory datastrukturer f√∂r snabb access
- Minimal memory footprint (endast unika nycklar)
- Optional persistence till PostgreSQL f√∂r historik

### 4. Query & Analysis API
- REST API f√∂r att h√§mta metadata
- Filter per signal type, service, milj√∂
- Export till JSON/YAML f√∂r vidare analys

### 5. Web UI (Future)
- Visualisera metadata-struktur
- Uppt√§ck kardinalitetsproblem
- J√§mf√∂r √∂ver tid

## Non-Goals

- **Inte en full observability backend** - anv√§nd Prometheus/Grafana f√∂r det
- **Inte en metrics aggregator** - aggregering sker i vanliga backends
- **Inte f√∂r production metrics collection** - verktyget √§r f√∂r analys

## Success Metrics

1. **Adoption**: Teams anv√§nder verktyget i CI/CD pipelines
2. **Cost reduction**: Teams identifierar och fixar kardinalitetsproblem
3. **Developer experience**: < 5 minuter fr√•n start till f√∂rsta insikt
4. **Performance**: Kan hantera 10K spans/sec p√• standard laptop

## Alternatives Considered

### Prometheus cardinality explorer
- **Pro**: Etablerat verktyg
- **Con**: Endast f√∂r metrics, kr√§ver full Prometheus stack

### Full observability backend
- **Pro**: Komplett l√∂sning
- **Con**: Overkill f√∂r enbart metadata-analys, dyr att k√∂ra

### Custom collector processor
- **Pro**: Kan integreras i befintlig pipeline
- **Con**: Sv√•rt att query och analysera historisk data

## Technical Constraints

- **Go 1.21+** f√∂r modern standardbibliotek
- **PostgreSQL 14+** f√∂r optional persistence
- **Linux/macOS/Windows** support
- **Low resource footprint** - ska kunna k√∂ras p√• developer laptops

## Timeline

### Phase 1: MVP (4-6 veckor)
- OTLP receiver (gRPC + HTTP)
- Basic metadata extraction
- In-memory storage
- Simple REST API

### Phase 2: Production Ready (2-3 veckor)
- PostgreSQL persistence
- Comprehensive testing
- Documentation
- Docker support

### Phase 3: Enhanced Features (Future)
- Web UI
- Alerting f√∂r nya h√∂ga-kardinalitetsattribut
- Integration med CI/CD
- Comparison tools

## Open Questions

1. **Retention policy**: Hur l√§nge ska metadata lagras?
   - F√∂rslag: 30 dagar default, konfigurerbar

2. **Multi-tenancy**: St√∂dja flera milj√∂er/teams i samma instans?
   - F√∂rslag: Phase 2 feature, filter p√• resource attributes

3. **Export format**: Vilka format beh√∂vs f√∂r integration?
   - F√∂rslag: JSON, YAML, CSV f√∂r Excel-analys

## References

- [OpenTelemetry Protocol Specification](https://opentelemetry.io/docs/specs/otlp/)
- [Cardinality in Prometheus](https://prometheus.io/docs/practices/naming/#labels)
- [OpenTelemetry Semantic Conventions](https://opentelemetry.io/docs/specs/semconv/)
