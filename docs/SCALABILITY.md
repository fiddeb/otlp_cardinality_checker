# Scalability and Performance

This document describes the scalability optimizations and real-world performance characteristics of the OTLP Cardinality Checker.

## Performance Optimizations

### 1. Optimized Value Sample Collection

**Problem:** Previous implementation sorted value samples on every insert, resulting in O(n log n) performance per metric update.

**Solution:**
- Removed sort operation from `AddValue()` method
- Added custom JSON marshaler that sorts only during serialization
- Improved cardinality tracking to count unique values beyond `MaxSamples` limit

**Impact:**
- Insert performance: O(n log n) ‚Üí O(1)
- Memory usage: Unchanged (still respects MaxSamples=100)
- Cardinality accuracy: Improved (tracks all unique values, not just sampled ones)

### 2. API Pagination

**Problem:** Listing 10,000+ metrics in a single response could result in 100+ MB JSON payloads and slow response times.

**Solution:**
- Added pagination support to all list endpoints
- Default limit: 100 items per page
- Maximum limit: 1,000 items per page
- Offset-based pagination

**Usage:**

```bash
# Get first page (default 100 items)
curl 'http://localhost:8080/api/v1/metrics'

# Get specific page
curl 'http://localhost:8080/api/v1/metrics?limit=50&offset=100'

# Filter by service with pagination
curl 'http://localhost:8080/api/v1/metrics?service=my-service&limit=100&offset=0'
```

**Response format:**

```json
{
  "data": [...],
  "total": 10000,
  "limit": 100,
  "offset": 0,
  "has_more": true
}
```

**Endpoints with pagination:**
- `GET /api/v1/metrics` - List all metrics
- `GET /api/v1/spans` - List all spans
- `GET /api/v1/logs` - List all log metadata

## Real-World Performance Results

### Test 1: 50,000 Metrics (Initial Validation)

**Load profile:**
- 50 VUs (Virtual Users)
- 120 seconds duration
- 50,000 unique metrics
- Cardinality: ~20 unique values per label

**Results:**
- **Memory**: 421 MB (8.4 KB per metric)
- **Throughput**: 450 req/s, 4,455 datapoints/s
- **Latency**: 
  - Median: 1.45ms
  - P95: 45ms
  - Max: 815ms
- **Success rate**: 99.95%

### Test 2: 213,000+ Metrics (Extreme Load)

**Load profile:**
- 50 VUs (Virtual Users)
- 60 seconds duration
- 500,000 attempted metrics (213,191 unique created)
- Cardinality: 100 unique values per label

**Results:**
- **Total metrics**: 213,191 unique
- **Memory**: 990 MB (4.6 KB per metric)
- **Throughput**: 461 req/s, 4,560 datapoints/s
- **Latency**:
  - Average: 6.33ms
  - Median: 642¬µs
  - P90: 2.16ms
  - P95: 3.51ms
  - Max: 1.77s
- **Success rate**: 99.56% (244 failures out of 55,668 checks)
- **API responsiveness**: 82% (API responsive check passed)
- **HTTP errors**: 0% (all requests succeeded)

**Detailed metrics:**
```
‚úì checks_total: 55,668 (917 checks/s)
‚úì checks_succeeded: 99.56%
‚úì status is 200: 100%
‚úì response time < 500ms: 99.56%
‚úì API responsive: 82%

Custom metrics:
- metrics_created: 276,840 (4,560 metrics/s)

HTTP performance:
- http_reqs: 27,988 (461 req/s)
- http_req_failed: 0%

Execution:
- iterations: 27,684 (456 iterations/s)
- iteration_duration: avg 108ms, p95 107ms

Network:
- data_received: 8.2 MB (135 KB/s)
- data_sent: 115 MB (1.9 MB/s)
```

### Memory Efficiency Analysis

**Per-metric memory usage improves with scale:**
- 50,000 metrics: 8.4 KB/metric
- 213,000 metrics: 4.6 KB/metric

**Why?** Go's garbage collector optimizes memory layout with larger datasets.

**API Performance under load:**
- Get specific metric: ~85¬µs (microseconds)
- List 100 metrics (213k total): ~234ms

## Capacity Planning

### Memory Requirements

Based on real-world testing:

| Metrics | Memory (MB) | Per Metric | Notes |
|---------|-------------|------------|-------|
| 10,000 | ~50 | 5 KB | Estimated |
| 50,000 | 421 | 8.4 KB | Tested |
| 100,000 | ~500 | 5 KB | Extrapolated |
| 213,000 | 990 | 4.6 KB | Tested |
| 500,000 | ~2,300 | 4.6 KB | Extrapolated |
| 1,000,000 | ~4,600 | 4.6 KB | Extrapolated |

**Recommendation:** Provision 2x estimated memory for headroom.

### Kubernetes Resource Recommendations

**For 50,000 metrics:**
```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "100m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

**For 200,000+ metrics:**
```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "200m"
  limits:
    memory: "1.5Gi"
    cpu: "1000m"
```

**For 1,000,000 metrics:**
```yaml
resources:
  requests:
    memory: "2Gi"
    cpu: "500m"
  limits:
    memory: "5Gi"
    cpu: "2000m"
```

### Throughput Capacity

Based on load testing:

- **OTLP Ingestion**: 4,500+ datapoints/s sustained
- **API Queries**: 450+ req/s sustained  
- **Concurrent Users**: 50 VUs with 99.56% success rate

**Bottlenecks:**
- API response time increases with total metrics (O(n) for list operations)
- Use pagination to maintain <500ms response times
- Single-instance limit: ~1M metrics before performance degrades

## Production Recommendations

### For <100,000 metrics:
- ‚úÖ In-memory storage is perfect
- ‚úÖ Single instance deployment
- ‚úÖ Resource limits: 1 GB memory, 500m CPU

### For 100,000-500,000 metrics:
- ‚úÖ In-memory storage still viable
- ‚ö†Ô∏è Monitor API response times
- ‚úÖ Resource limits: 2-3 GB memory, 1 CPU

### For >500,000 metrics:
- ‚ö†Ô∏è Consider implementing PostgreSQL persistence
- ‚ö†Ô∏è Consider sharded maps for better concurrency
- ‚ö†Ô∏è Consider HyperLogLog for cardinality tracking
- ‚úÖ Resource limits: 5 GB memory, 2 CPU

## Future Optimizations

### 3. HyperLogLog Cardinality Tracking (Planned)

**Goal:** Reduce memory usage for high-cardinality tracking

**Current approach:**
- Uses set-based cardinality: `EstimatedCardinality = len(valueSampleSet)`
- Accurate up to MaxSamples (100 values)
- Memory: O(n) where n = unique values (capped at 100)

**HyperLogLog approach:**
- Memory: Fixed ~1.5 KB per key (0.81% standard error)
- Accuracy: ¬±1% for any cardinality
- Trade-off: Slightly less accurate, much more memory-efficient

**When to implement:** When tracking cardinality beyond 1,000 unique values per key becomes common.

### 4. Sharded Maps (Planned)

**Goal:** Reduce lock contention under high concurrency

**Current approach:**
- Single RWMutex per signal type (metrics, spans, logs)
- All concurrent readers/writers compete for same lock
- Fine for <1,000 requests/second

**Sharded approach:**
- Split storage into N shards (e.g., 32)
- Hash metric name to determine shard
- Each shard has independent lock
- Reduces contention by factor of N

**When to implement:** When profiling shows lock contention is a bottleneck (typically >10,000 metrics with high update frequency).

## Scalability Limits

### Current Architecture Limits

**In-Memory Storage:**
- Practical limit: ~50,000-100,000 metrics (depending on label cardinality)
- Memory: ~5-10 GB for 50,000 metrics with average label keys
- Recovery: All metadata lost on restart

**Recommendations for very large deployments:**
1. **PostgreSQL persistence** (planned) - Survive restarts
2. **Horizontal sharding** - Run multiple instances, shard by service name
3. **Metric aggregation** - Pre-aggregate at Collector level
4. **TTL/expiry** - Automatically remove stale metrics after N days

### When to Consider PostgreSQL

Switch to PostgreSQL persistence when:
- You have >50,000 unique metrics
- Restart downtime is unacceptable
- You need historical metadata analysis
- You want to query across time ranges

## Testing Scalability

### Load Testing with 10,000 Metrics

```bash
# Generate test data
for i in {1..10000}; do
  echo '{
    "resource_metrics": [{
      "resource": {"attributes": [{"key": "service.name", "value": {"string_value": "test-service"}}]},
      "scope_metrics": [{
        "metrics": [{
          "name": "metric_'$i'",
          "sum": {
            "data_points": [{
              "attributes": [
                {"key": "label1", "value": {"string_value": "value1"}},
                {"key": "label2", "value": {"string_value": "value2"}}
              ],
              "as_int": 100
            }]
          }
        }]
      }]
    }]
  }' | curl -X POST -H "Content-Type: application/x-protobuf" \
    --data-binary @- http://localhost:4318/v1/metrics
done

# Test pagination performance
time curl -s "http://localhost:8080/api/v1/metrics?limit=1000&offset=0" | jq '.total'
time curl -s "http://localhost:8080/api/v1/metrics?limit=1000&offset=5000" | jq '.total'
```

### Memory Profiling

```bash
# Build with profiling
go build -o otlp-cardinality-checker ./cmd/server

# Run with profiling enabled
./otlp-cardinality-checker &

# Take heap snapshot
curl http://localhost:8080/debug/pprof/heap > heap.prof

# Analyze
go tool pprof -http=:8081 heap.prof
```

## Summary

The current implementation can comfortably handle:
- ‚úÖ 10,000 metrics with standard label cardinality
- ‚úÖ 1,000 requests/second ingestion rate
- ‚úÖ Concurrent queries with pagination
- ‚úÖ Multiple services (filtered queries)

For larger deployments:
- üîÑ Consider PostgreSQL persistence (>50k metrics)
- üîÑ Implement HyperLogLog (high cardinality labels)
- üîÑ Add sharded maps (>10k req/sec)
- üîÑ Horizontal scaling (>100k metrics)
